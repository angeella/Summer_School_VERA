---
title: "<img src=\"unive_0.jpg\" /> Network manipulation in R"
author: | 
  | Angela Andreella 
  | Ca' Foscari University of Venice
  | angela.andreella@unive.it
date: '2024-07-02'
output:
  prettydoc::html_pretty:
    theme: tactile
    highlight: github
    df_print: paged
    toc: true
    number_sections: true
fontsize: 11pt
geometry: margin = 1in
---

<style type="text/css">
.main-container {
  max-width: 1100px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, fig.align = "center", out.width = '80%', warning = F, message = F)
```


For creating, decorating, and assessing basic proprieties of network graph, the package `igraph` is particularly useful. It contains functions for (relatively!) straightforward implementation and rapid prototyping of graph algorithm, and allows for the fast handling of large graphs (e.g., on the order of millions of vertices and edges).

```{r, eval = FALSE}
install.packages("igraph") 
```

```{r}
library(igraph)
```


Thought the tutorial, we consider a graph as $G = (V,E)$ with a set $V$ of vertices and a set $E$ of edges, where elements of $E$ are unordered pairs $\{u,v\}$ of distinct vertices $u,v \in V$. The number of vertices $N_v = |V|$ and the number of edges $N_e = |E|$. Often, and without loss of
generality, we will label the vertices simply with the integers $1, \dots, N_v$, and the edges, analogously.



# An example of network: 3 million Russian troll tweets

In this tutorial, we will analyze data used in the *FiveThirtyEight* story [Why We’re Sharing 3 Million Russian TrollTweets](https://fivethirtyeight.com/features/why-were-sharing-3-million-russian-troll-tweets/). The original data set is composed by $3$ million of tweets from suspected twitter account. The data are prepossessed, if you want to see the original data set, please see this [link](https://www.kaggle.com/fivethirtyeight/russian-troll-tweets).

We want to analyze the interaction structure between these twitter profiles, excluding (in this case):

- the interaction (comment/re tweet), 

- the direction, and 

- the number of time this interaction appear (size of the edge).

You can find the dataset `russian_trolls` as `.RData` in the  `Lab02/Datasets` folder: 

```{r}
load("Datasets/russian_trolls.RData")
```

It is composed by two matrices:

1. `Y` describes the edges (2-column matrix, where each row defines one edge)

2. `X` reports some information about the nodes (i.e., twitter profiles, $1245$ in total):

  - `accountcategory`: main category for type of account, e.g., Commercial, NewsFeed, etc (macro category);

  - `accounttype`: type of account (thinner account category than `accountcategory`);

  - `activity`: number of activities;

  - `maxfollowers`: maximum number of followers profiles;

  - `maxfollowing`: maximum number of following profiles;

  - `minfollowers`: minimum number of followers profiles;

  - `minfollowing`: minimum number of following profiles;
  
  - `maxpostdate`: last registered post;

  - `minpostdate`: first registered post;

  - `vertex.names`: name of the twitter account (i.e., the name of the node of the graph).

# Edge, vertex and attributes

Let transform our data set as an `igraph` class object:

:::: {style="display: grid; grid-template-columns: auto auto; grid-column-gap: 5px; place-items: start;"}
::: {}
__R commands__ 

```{r}
net = graph_from_edgelist(Y, directed = F) 

for(j in 1:ncol(X)){ 
  net = net %>% 
    set_vertex_attr(name = colnames(X)[j],
                    value = X[,j]) 
}

V(net)$name = V(net)$vertex.names 
```
:::
::: {}
__Comments__ 

* `graph_from_edgelist(x)` -- creates a graph from a two column matrix `x`.
* `set_vertex_attr(name = x, value = y)` -- set vertex attributes, where `x` is the name of the attribute, and `y` is the value of the attribute.
* In the last line we name the nodes using the variable `vertex.names`, we can access to the vertex-level name of the graph `x` attribute by `V(x)$name`.
:::
::::

> `r emo::ji("boom")` **_Please note_** _you can create the `igraph` class object also if you have a data.frame thanks to the `graph_from_data_frame` function (or you can transform the edgelist as data.frame or reverse). There is also the function `graph_from_adjacency_matrix` to create an `igraph` graph object from adjacency matrices._

Let's take a look of our new graph:

```{r}
summary(net)
```

The `igraph` objects is described by four letters:

1. *D* or *U* for directed or undirected graph;
2. *N* for named graph (where nodes have a name attribute);
3. *W* for a weighted graph (where edges have a weight attribute);
4. *B* for a bipartite graph (in short: two disjoint sets of nodes where each node of a set is connected with another node in the other set).

So, there are two numbers ($1245$ and $2857$) which refer to the number of nodes and edges in the graph.

Then, we have the list of node and edge attributes. For example (v/c) is vertex-level character attribute.

With

```{r}
ecount(net) 
vcount(net)
```

you can compute the total number of edges $N_e$ and vertices $N_v$ respectively.

Before we saw how see the vertex-level attribute `name`. You can access to nodes, edges and their attributes by:


:::: {style="display: grid; grid-template-columns: auto auto; grid-column-gap: 5px; place-items: start;"}
::: {}
__R commands__ 

```{r}
E(net) 
V(net)
list.vertex.attributes(net)
```
:::
::: {}
__Comments__ 

* `E(x)`: call the edge sequence of graph `x`;
* `V(x)`: call the vertex sequence of graph `x`;
* `list.vertex.attributes(x)`: return the list names of vertex attributes of graph `x `.
:::
::::

# Vertex Characteristics

First of all, we will eliminate the nodes without connections, i.e., degree equals $0$.

> `r emo::ji("star")` **Remember**: The degree indicates the number of adjacent to which the node is connected. It measures how connected a node is, so it is a local measure.

:::: {style="display: grid; grid-template-columns: auto auto; grid-column-gap: 5px; place-items: start;"}
::: {}
__R commands__ 

```{r}
net = delete_vertices(net, which(igraph::degree(net) < 1))
```
:::
::: {}
__Comments__ 

* `delete_vertices(x, y)`: Delete vertices `y` from a graph `x`;
* `degree(x)`: compute the degree for each node of graph `x`;
* `which(igraph::degree(x) < 1)`: return the index where the nodes of the graph `x` has degree less than $1$. 
:::
::::

Then, also we can see which are the nodes with 5 highest degree:

```{r}
D_net = igraph::degree(net)
sort(D_net,decreasing = T)[1:5]
```

So, `r names(sort(D_net,decreasing = T)[1:5])` can be seen as the most 5 connected twitter accounts, `r names(sort(D_net,decreasing = T)[1])` is connected with 244 twitter accounts.

We can represent the degree nodes in a histogram:

```{r}
par(mfrow=c(1,2))
hist(D_net,nclass = 100, main = "Degree distribution", xlab = "Degree")
hist(igraph::degree(net,normalized = T),nclass=100, main = "Degree distribution (normalized)", xlab = "Normalized degree")
```

The normalized degrees are simply the degrees divided by $(N_v-1)$ where $N_v$ is the number of nodes. So, we have a measure with range $[0,1]$.


We can compute also the **graph density**, which is the ratio of the number of edges and the number of possible edges (i.e., it is a **global measure**):

```{r}
edge_density(graph = net)
```


The network follows a **power-law structure**, where the distribution of the nodes has an exponential decay as the degree increases: many nodes have a small number of connections ($1$ or $2$), while a small number of nodes have many. 

Clearly the shape of the distribution does not change when considering the normalized or absolute quantity. The distribution of normalized degrees, however, allows us to observe that even the most connected nodes present a small number of connections, compared to the size of the network. This result is not surprising, if we consider that the density of the network is about $0.004$. That is, of all the possible connections, we observe approximately $4$ out of $1000$.

Given the nature of the decay in this distribution, a log–log scale is more effective in summarizing the degree information.

```{r}
par(mfrow= c(1,1))
dd.net <- degree_distribution(net)
d <- 1:max(degree(net))-1
ind <- (dd.net != 0)
plot(d[ind], dd.net[ind], log="xy", col="blue",
xlab=c("Log-Degree"), ylab=c("Log-Intensity"),
main="Log-Log Degree Distribution")
```

We see that there is a fairly linear decay in the log-frequency as a function of log-degree. 

Beyond the degree distribution itself, it can be interesting to understand the manner in which vertices of different degrees are linked with each other. Useful in assessing this characteristic is the notion of the **average degree of the neighbors of a given vertex**.

```{r}
a.nn.deg.net <- knn(net,V(net))$knn
plot(degree(net), a.nn.deg.net, log="xy",
col="goldenrod", xlab=c("Log Vertex Degree"),
ylab=c("Log Average Neighbor Degree"))
```

> What can we say?

There is a tendency for vertices of higher degrees to link with vertices with lower degrees, vertices of lower degree tend to link with vertices of both lower and higher degrees.

A fundamental concept is also the **geodesic distance**. The `igraph` library computes this quantities efficiently. For example, to calculate the path connecting two nodes:

```{r}
shortest_paths(graph = net,from = "aiden7757",to = "_nickluna_")$vpath
```

So, the shortest path includes $5$ vertices names `aiden7757`, ` andyhashtagger`, `bgarner2107`, `politweecs` and `_nickluna_`.

> `r emo::ji("star")` **Remember**: The geodesic distance is the length of the shortest path connecting two nodes.

We are now interested to compute the **mean distance between nodes**, i.e., the mean length of the paths:

```{r}
mean_distance(graph = net)
```

> `r emo::ji("star")` **Remember**: Average path length is a concept in network topology that is defined as the average number of steps along the shortest paths for all possible pairs of network nodes.

So the average path length equals $5.15$. Also, we can compute the matrix $S$ of total distances between all possible couples of nodes:

```{r}
par(mfrow = c(1,1))
S = distances(graph = net)
image(S,col = gray.colors(n = diameter(net))) 
#The diameter of a graph is the length of the longest geodesic.
```


Many questions that might be asked about a vertex in a network graph essentially seek to understand its *importance* in the network. 

Measures of centrality are designed to quantify such notions of *importance*. 

There are a vast number of different centrality measures that have been proposed over the years. We have already encountered what is arguably the most widely used measure of vertex centrality: vertex degree. Here we will see:

- **Closeness centrality**: how many steps is required to access every other vertex from a given vertex, i.e., how easily a node can reach other nodes. It measures attempt to capture the notion that a vertex is *central*
if it is *close* to many other vertices.

$$
C_{Cl}(v) = \dfrac{1}{\sum_{u \in V} \text{dist}(v, u)}
$$
where $\text{dist}(v,u)$ is the geodesic distance between the vertices $u$, $v \in V$. Often, for comparison across graphs and with other centrality measures, this measure is normalized to lie in the interval $[0,1]$, through multiplication by a factor $N_v−1$.


- **Betweenness centrality**: analyze the number of geodesics (shortest paths) going through a vertex or an edge, i.e., how relevant is a node in terms of connecting other nodes in a graph. It measures are aimed at summarizing the extent to which a vertex is located *between* other pairs of vertices. These centralities are based upon the perspective that *importance* relates to where a vertex is located with respect to the paths in the network graph. If we picture those paths as the routes by which, say, communication of some sort or another takes place, vertices that sit on many paths are likely more critical to the communication process.

$$
C_{B}(v) = \sum_{s \ne t \ne v \in V} \dfrac{\sigma(s, t \mid v)}{\sigma(s,t)}
$$
where $\sigma(s, t \mid v)$ is the total number of shortest paths between $s$ and $t$ that pass through $v$, and $\sigma(s, t)$ is the total number of shortest paths between $s$ and $t$ (regardless of whether or not they pass through $v$).

In the event that shortest paths are unique, $C_{B}(v)$ just counts the number of shortest paths going through $v$. This centrality measure can be restricted to the unit interval through division by a factor of $(N_v−1)(N_v−2)/2$.

```{r}
C_net = igraph::closeness(graph = net, normalized = TRUE)
B_net = igraph::betweenness(graph = net,normalized = TRUE) 
```

So, let's see now the distribution of the closeness and betweeness measure:

```{r}
par(mfrow=c(1,2))
hist(C_net, breaks = 50)
hist(B_net, breaks = 50)
```

```{r}
names(which.max(C_net))
names(which.min(C_net))
```

So, the account `ann_hanah` is the node closest to the other, while `jeromyjerom` is the less one.

```{r}
names(which.max(B_net))
names(which.min(B_net))
```

So, the account `matevidence` is the most relevant node in our graph in terms of connecting nodes, while `_anna_sanna_` the less one (gatekeepers of information).

An intuitively appealing way of displaying vertex centralities (for networks of small to moderate size) is to use a radial layout, with more central vertices located closer to the center. The function `gplot.target`, in the package `sna`, can be used
for this purpose. For example (DO NOT RUN),

```{r, eval = FALSE}
net.sub <- delete_vertices(net, vertex.attributes(net)$accounttype != "left")

A <- as_adjacency_matrix(net.sub, sparse=FALSE)
sna::gplot.target(A, sna::degree(A))
```

The visualizations of the other centralities measures are produced similarly, replacing the argument `degree(A)` by the arguments `closeness(g)`, `betweenness(g)`.

It is possible that we have group of nodes disconnected, in order to see how our network is composed we can use the `components()` function:

```{r}
subg = igraph::components(graph = net)
subg$csize
```

The network we are analyzing has one very extensive component, consisting of $1149$ nodes, and several components consisting of very few nodes ($2$ or $4$). There is also a component formed by $35$ nodes, which forms an isolated group and which may be interesting to analyse at a later date. For the moment, we focus only on the largest component, excluding the other nodes from the analysis. We recalculate the statistics mentioned above and evaluate which nodes are associated with higher values.

```{r}
net = igraph::delete_vertices(net, which(subg$membership != 1))
C_net = igraph::closeness(graph = net,normalized = T)
B_net = igraph::betweenness(graph = net,normalized = T)
D_net = igraph::degree(net,normalized = T)
```

```{r}
sort(C_net,decreasing = T)[1:5]
sort(D_net,decreasing = T)[1:5]
sort(B_net,decreasing = T)[1:5]
```

> What happened?

So, let's see now the distribution of the closeness and betweeness measure:

```{r}
par(mfrow=c(1,2))
hist(C_net, breaks = 50)
hist(B_net, breaks = 50)
```

Closeness presents a bimodal distribution, with one around $0.16$ and another on higher values. Betweenness, on the other hand, presents a strongly asymmetrical distribution.

For example,

```{r}
sum(B_net > .1)
```

We observe that only 6 nodes have a betweennes greater than $0.1$. We might also ask if and how these statistics are related. 


> **_Question:_** _As as the degree increases, so do betwennes and closeness?_

Let's compute the correlation between these measures:

```{r}
cor(cbind(B_net,D_net,C_net))
```

and corresponding pair plots:

```{r}
library(GGally)
ggpairs((data.frame(B_net,D_net,C_net))) + theme_bw()
```

The data suggest that there is some association between **degree** and **betweennes**: nodes with a higher number of connections (degree) are more likely to lie on the shortest paths between other pairs of nodes (betweeness).

If there is a strong positive correlation between **degree** and **closeness**: Nodes that have many direct connections to other nodes in the graph (high degree) are also more centrally located in terms of their overall proximity to other nodes (high closeness centrality).

If there is a strong positive correlation between **betweennes** and **closeness**: Nodes that are well positioned to carry out a rapid transfer of information within the graph (high closeness centrality) are also those that play a crucial role in controlling communications between different nodes (high betweenness centrality).

# Edges characteristics

All of the summary measures discussed so far (i.e., degree and other, more general, notions of centrality) are for vertices, as it seems to be most common in practice that questions of importance are in regard to the vertices of a graph. But some questions are more naturally associated with edges.

We might ask which ties in the network are most important for the spread of, say, information or rumors. Edge betweenness centrality—which extends vertex betweenness centrality in a straightforward manner, by assigning to each edge a value that reflects the number of shortest paths traversing that edge—is a natural quantity to use here.

```{r}
eb <- edge.betweenness(net)
E(net)[order(eb, decreasing=T)[1:3]]
```
The account matevidence plays a key role in facilitating the direct flow of information between lil_game_vip and ndr_bolozyb.

However, many other vertex centrality measures do not extend as easily. See Chap. 3 of the edited volume of [Brandes and Erlebach](https://link.springer.com/book/10.1007/b106453) for a brief discussion.



# Network cohesion

A great many questions in network analysis boil down to questions involving network cohesion, the extent to which subsets of vertices are cohesive—or *stuck together*—with respect to the relation defining edges in the network graph.

There are many ways that we can define **network cohesion**, depending on the context of the question being asked. Definitions differ, for example, in scale, ranging from local (e.g., triads) to global (e.g., giant components), and also in the extent to which they are specified explicitly (e.g., cliques) versus implicitly (e.g., ‘clusters’ or ‘communities’). 


One approach to defining network cohesion is through specification of a certain subgraph(s) of interest. The canonical example of such a subgraph is that of a clique.
Recall that cliques are complete subgraphs and hence are subsets of vertices that are fully cohesive, in the sense that all vertices within the subset are connected by edges.

A census of cliques of all sizes can provide some sense of a ‘snapshot’ of how structured a graph is.

```{r}
table(sapply(cliques(net), length))
```
We have 1149 nodes (cliques of size 1), 2587 edges (cliques of size two) and 1588 triangles (cliques of size 3). The largest cliques are of size 6, of which there are 21

```{r}
cliques(net)[sapply(cliques(net), length) == 6][[1]]
cliques(net)[sapply(cliques(net), length) == 6][[2]]
cliques(net)[sapply(cliques(net), length) == 6][[3]]
```
Considering the first three cliques of size 6, we can note that they shared several nodes.

Note that there is some redundancy here, in that the cliques of larger sizes necessarily include cliques of smaller sizes. 

A **maximal** clique is a clique that is not a subset of a larger clique.

```{r}
table(sapply(maximal.cliques(net), length))
```
With

```{r}
clique.number(net)
```
you can see the size of the largest clique.

We can also compute a $k$-core, i.e., a subgraph of $G$ for which all vertex degrees are at least $k$, and such that no other subgraph obeying the same condition contains it (i.e., it is maximal in this property).

```{r}
cores <- coreness(net)
hist(cores)
```

The characterizations of network cohesion described so far proceed by first stating a pre-specified notion of substructure and then looking to see whether it occurs in a graph $G$ and, if so, where and how often. More generally, the related concept of relative frequency can be applied in various useful ways.

The density of a graph is the frequency of realized edges relative to potential edges. In a undirected graph $G$ with no self-loops and no multiple edges, the density of a subgraph $H = (V_H, G_H)$ is:

$$
\text{den}(H) = \dfrac{\mid E_H \mid}{\mid V_H \mid (\mid V_H \mid -1)/2}
$$
The value of $\text{den}(H)$ will lie between zero and one and provides a measure of how close $H$ is to being a clique.

Taking $H=G$:

```{r}
graph.density(net)
```
Taking $H=H_v$ to be the set of neighbors of a vertex $v \in V$, and the edges between them:

```{r}
sub.net <- induced.subgraph(net, igraph::neighborhood(net, 1, which(V(net)$accounttype == "left"))[[2]])
graph.density(sub.net)
```
```{r}
sub.net <- induced.subgraph(net, igraph::neighborhood(net, 1, which(V(net)$accounttype == "right"))[[1]])
graph.density(sub.net)
```

Another measure is the **transitivity** which is a measure of global clustering, summarizing the relative frequency with which connected triples close to form triangles:

$$
\text{cl}_T(G) = \dfrac{3 \tau_{\Delta} (G)}{\tau_3 (G)}
$$
where $\tau_{\Delta} (G)$ is the number of trinagles in the graph $G$, and $\tau_3 (G)$ is the number of connected triples (i.e., a subgraph of three vertices connected by two edges).

```{r}
transitivity(net)
```

So about $0.05$ of the connected triples close in this manner. 

The local analogue of this measure can also be of interest. Let $\tau_{\Delta}(v)$ denote the number of triangles in $G$ into which $v \in V$ falls, and $\tau_3(v)$ the number of connected triples in $G$ for which the two edges are both incident to $v$.

$$
\text{cl}(v) = \dfrac{\tau_{\Delta}(v)}{\tau_3(v)}
$$
```{r}
transitivity(net, "local", vids = which(V(net)$accounttype == "left")[2])
```

# Graph Partitioning

Partitioning refers to the segmentation of a set of elements into *natural* subsets. 

In the analysis of network graphs, partitioning is a useful tool for finding, in an unsupervised fashion, subsets of vertices that demonstrate a *cohesiveness* with respect to the underlying relational patterns

This problem of graph partitioning is also commonly referred to as **community detection** in the complex networks literature.

A *cohesive* subset of vertices generally is taken to refer to a subset of vertices that

(i) are well connected among themselves, and at the same time
(ii) are relatively well separated from the remaining vertices.

Graph partitioning algorithms typically seek a partition $\mathcal{C} = \{C_1, \dots, C_K\}$ of the vertex set $V$ of a graph $G = (V,E)$ in such a manner that the sets $E(C_k, C_{k^\prime})$ of edges connecting vertices in $C_k$ to vertices in $C_{k^\prime}$ are relatively small in size compared to the sets $E(C_k) = E(C_k, C_K)$ of edges connecting vertices within the $C_k$.

The Russian troll network is clearly characterized by different groups. Of particular interest is, for instance, the type of account (i.e., `accounttype` variable), which is divided into several macro-categories. There is also a less fine division, i.e., the `accountcategory` variable.

```{r}
aType = vertex_attr(graph = net,name="accounttype")
```

```{r}
table(aType)
```


We clean up the various strings with the use of some regular expressions. Note that `$ ` makes a match for an empty string (`^` represents the beginning of a line,`$` the end), and that the $?$ must be preceded by the escape characters `\`.

```{r}
require(stringr)
aType = str_to_title(aType)
aType = str_replace(aType,"Ukranian","Russian")
aType = str_replace(aType,"Commercial|Local","News")
aType = str_replace(aType,"Koch","Fear")
aType = str_replace(aType,"^$|Arabic|\\?", "Other")
table(aType)
```

At this point, we may be interested in some characteristics of our groups. 

> **_Question:_** _How does the distribution of degree, betweeness and  closeness centrality vary between the three largest groups?_

```{r}
require(tidyverse)
df_pl = data.frame(den=D_net, clos = C_net, bet = B_net, x=aType)
#gather(df_pl,"den","clos","bet")
df_pl %>% dplyr::filter(x %in% c("Right","Left","Russian")) %>%
gather(.,"den","clos","bet",key="stat",value = "value") %>%
ggplot(aes(value,after_stat(density),color=x)) + 
  geom_freqpoly(lwd=1)+ 
  facet_wrap(~stat,scales="free")+ 
  theme_bw()
```

In general we do not expect there to be much difference from these statistics if the communities represent reasonable social groups. The three groups are homogeneous with respect to degree and betweenness, while they differ somewhat in with respect to closeness. Thus, we can conclude that the group of trolls categorized as Left are less close to each other than the others. This characteristic is in itself interesting, and suggests that this group is less compact and therefore also more open to connections with the outside world. To explore these considerations further, we could evaluate for instance, how the geodesic distance varies between the two groups, and whether these differences are due only to a few nodes.

A natural question at this point is whether the division into groups is "good" in terms of cohesion.

```{r}
modularity(net,factor(aType))
assortativity(net,factor(aType))
```

> `r emo::ji("star")` **Remember**:
- *modularity*: Fraction of edges connecting nodes in the same group minus the expected value of the same quantity in a network with random connections: high modularity $\rightarrow$ strong distinct defined communities.
- *assortativity*: measures the level of homophyly of the graph, based on some vertex labeling or values assigned to vertices. If the coefficient is high, that means that connected vertices tend to have the same labels or similar assigned values.

The division actually leads to very high values of *assortativity*, confirming a strong homophily with respect to the group. 

This result confirms that trolls tend to interact more with others belonging to the same political sphere or sphere of interest, creating many connections between profiles that are similar to them and few with those that are different.


**Can we do better?** 

We try to obtain a more interesting partition by estimating the groups on the basis of connections (the groups from before do not use this information!).

**Objective**: To divide the network into communities of nodes, so that nodes within each community have many connections between them, while nodes in different communities have few connections. There are a lot of approaches:

- *Louvain method*

- *Stochastic block models*

- *Spectral methods*

- etc

Here, we will apply the first one, the Louvain method, we will not go into details, but it find community (subgraphs) optimazing the modularity measure.

Large values of the modularity are therefore taken to suggest that $\mathcal{C}$ captures nontrivial ‘group’ structure, beyond that expected to occur under the random assignment of edges.


```{r}
gr = cluster_louvain(graph = net)
#gr2 = cluster_fast_greedy(graph = net) #agglomerative hierarchical clustering algorithm
```

Note that the `cluster_louvain(x)` function as other `cluster_` function of the package `igraph` returns and object of class `communities`:

```{r}
class(gr)
```

This is useful since if we have a `communities` class object, we can call other operations related to this class like:

- `membership(x)`: gives the division of the vertices, into communities. It returns a numeric vector, one value for each vertex, the id of its community. Community ids start from one;

- `modularity(x)`: gives the modularity score of the partitioning.

```{r}
table(membership(gr))
assortativity(net,membership(gr))
```

The method identifies $K=9$ communities (too many?), and produces a partition with very high *modularity*:

```{r}
modularity(gr)
```

So, summing up  `modularity(x)` can take as input the graph with the membership vector of the community structure or directly the `community` objects.

```{r}
net1 <- net
vertex_attr(net1)$name  <- NULL
gr1 = cluster_louvain(graph = net1)
plot(gr1, net1,col = NULL)
```


> **_Question:_** _What is the relationship between the groups identified by the *Louvain* method and those referred to the sphere of influence, i.e., the `aType` variable?_ 


```{r}
table(membership(gr), aType)
```

> `r emo::ji("boom")` **Please note**! _If you do not have a large graph (i.e., graphs with up to fifty vertices), you can use the `cluster_optimal` function which calculates the optimal community structure of a graph, by maximizing the *modularity* measure over all possible partitions._

# Concluding

> `r emo::ji("boom")` **_Please note_** _save your workspace! We will use the objects created now in the next tutorial._

```{r}
save(list = ls(), file = "lab02.RData")
```
